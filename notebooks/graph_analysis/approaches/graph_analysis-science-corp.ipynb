{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graphical Analysis of GitHub Repositories and Contributors\n",
    "\n",
    "In this notebook, we programatically view the connections between open source projects, determine project clusters, and map out technology ecosystems. We explore the Augur GitHub data to view relationships between open source projects and communities by studying graphs based on relations such as common contributors and project activities between different GitHub repositories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Augur database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Until the Operate First enviroment can connect to the DB, use config file to access. Do not push config file to Github repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "import collections\n",
    "from functools import reduce\n",
    "\n",
    "import sqlalchemy as salc\n",
    "import json\n",
    "import os\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "with open(\"../../../config.json\") as config_file:\n",
    "    config = json.load(config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_connection_string = 'postgresql+psycopg2://{}:{}@{}:{}/{}'.format(config['user'], config['password'], config['host'], config['port'], config['database'])\n",
    "\n",
    "dbschema='augur_data'\n",
    "engine = salc.create_engine(\n",
    "    database_connection_string,\n",
    "    connect_args={'options': '-csearch_path={}'.format(dbschema)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve Available Repositories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset repositories based on a category\n",
    "# Selecting repositories that fall under the Containers org on Github\n",
    "repo_git_set = []\n",
    "repo_name_set = []\n",
    "science_repo_sql = salc.sql.text(f\"\"\"\n",
    "                 SET SCHEMA 'augur_data';\n",
    "                    --science \n",
    "                    select repo_git from repo a, \n",
    "                    (\n",
    "                    SELECT \n",
    "                    \tC.repo_id\n",
    "                    FROM\n",
    "                    \taugur_operations.users A,\n",
    "                    \taugur_operations.user_groups b,\n",
    "                    \taugur_operations.user_repos C \n",
    "                    WHERE\n",
    "                    \tA.user_id = b.user_id \n",
    "                    \tAND b.group_id = C.group_id \n",
    "                    \tAND b.name='science'\n",
    "                    \t--AND lower(A.login_name)='numfocus'\n",
    "                    ORDER BY\n",
    "                    \tA.login_name,\n",
    "                    \tb.group_id) b \n",
    "                    \twhere a.repo_id = b.repo_id; \n",
    "                            \"\"\")\n",
    "\n",
    "#t = engine.execute(repo_query)\n",
    "with engine.connect() as conn:\n",
    "    #df = pd.read_sql(sql, cnxn)\n",
    "    results = conn.execute(science_repo_sql)\n",
    "    df_results = pd.DataFrame(results) \n",
    "    \n",
    "#id_count = results.first()[0]\n",
    "#print(id_count) \n",
    "print(df_results)\n",
    "#repo_gits = results[repo_git]\n",
    "\n",
    "#print(results)\n",
    "#num_fields = len(results)\n",
    "#field_names = [i[0] for i in results.description]\n",
    "\n",
    "#print(num_fields)\n",
    "#print(field_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for row in df_results: \n",
    "#    print(results)\n",
    "#    #results = results.mappings().all()[0]\n",
    "#    repo_git = df_results['repo_git']\n",
    "#    repo_git_set.append(repo_git)\n",
    "\n",
    "#print(repo_git_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_set=[]\n",
    "#print(df_results[repo_git])\n",
    "\n",
    "for index, row in df_results.iterrows():\n",
    "    #print(row[\"repo_git\"])\n",
    "    trepo_git=row[\"repo_git\"]\n",
    "    #print(trepo_git) \n",
    "    \n",
    "#for repo_git in df_results:\n",
    "    #print(df_results[repo_git])[repo_git]\n",
    "    repo_query = salc.sql.text(f\"\"\"\n",
    "                 SET SCHEMA 'augur_data';\n",
    "                 SELECT \n",
    "                    b.repo_id,\n",
    "                    b.repo_name\n",
    "                FROM\n",
    "                    repo_groups a,\n",
    "                    repo b\n",
    "                WHERE\n",
    "                    a.repo_group_id = b.repo_group_id AND\n",
    "                    b.repo_git = '{trepo_git}'\n",
    "        \"\"\")\n",
    "\n",
    "    #t = engine.execute(repo_query)\n",
    "    with engine.connect() as conn:\n",
    "        results = conn.execute(repo_query)\n",
    "        df2_results = pd.DataFrame(results) \n",
    "        #df2_results.dtypes\n",
    "    #print(df2_results)\n",
    "    \n",
    "    #results = t.mappings().all()[0]\n",
    "    #range(results)\n",
    "    #len(results)\n",
    "    #print(df2_results)\n",
    "    #results = results.mappings().all()[0]\n",
    "    #dataFrame.to_string(index=False)\n",
    "    df2_results.reset_index(drop=True, inplace=True) \n",
    "    repo_id = int(df2_results['repo_id'].values)\n",
    "    #print(repo_id)\n",
    "    repo_name = df2_results['repo_name'].to_string(index=False)\n",
    "    repo_set.append(repo_id)\n",
    "    #print(repo_id)\n",
    "    #print(repo_name)\n",
    "    repo_name_set.append(repo_name)\n",
    "#print(repo_id_set)\n",
    "#print(repo_name_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve Issue Contributors\n",
    "\n",
    "We will now fetch all Issue contributors for various repositories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "issue_contrib = pd.DataFrame()\n",
    "for repo_id in repo_set:\n",
    "    repo_query = salc.sql.text(f\"\"\"\n",
    "                SET SCHEMA 'augur_data';\n",
    "                SELECT r.repo_id,\n",
    "                r.repo_git,\n",
    "                i.reporter_id as cntrb_id,\n",
    "                i.issue_id\n",
    "                FROM\n",
    "                repo r, issues i\n",
    "                 WHERE\n",
    "                i.repo_id = {repo_id} AND\n",
    "                i.repo_id = r.repo_id\n",
    "        \"\"\")\n",
    "    df_current_repo = pd.read_sql(repo_query, con=engine)\n",
    "    issue_contrib = pd.concat([issue_contrib, df_current_repo])\n",
    "\n",
    "issue_contrib = issue_contrib.reset_index()\n",
    "issue_contrib.drop(\"index\", axis=1, inplace=True)\n",
    "issue_contrib.columns =['repo_id', 'repo_git', 'cntrb_id', 'issue_id']\n",
    "display(issue_contrib)\n",
    "issue_contrib.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve PR Contributors\n",
    "\n",
    "We will now fetch all the PR contributors for various repositories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_contrib = pd.DataFrame()\n",
    "\n",
    "for repo_id in repo_set:\n",
    "    repo_query = salc.sql.text(f\"\"\"\n",
    "                SET SCHEMA 'augur_data';\n",
    "                SELECT r.repo_id,\n",
    "                r.repo_git,\n",
    "                prm.cntrb_id,\n",
    "                prm.pull_request_id\n",
    "                FROM\n",
    "                repo r, pull_request_meta prm\n",
    "                WHERE\n",
    "                prm.repo_id = {repo_id} AND\n",
    "                prm.repo_id = r.repo_id\n",
    "                LIMIT 50000\n",
    "        \"\"\")\n",
    "    df_current_repo = pd.read_sql(repo_query, con=engine)\n",
    "    pr_contrib = pd.concat([pr_contrib, df_current_repo])\n",
    "\n",
    "pr_contrib = pr_contrib.reset_index()\n",
    "pr_contrib.drop(\"index\", axis=1, inplace=True)\n",
    "pr_contrib.columns =['repo_id', 'repo_git', 'cntrb_id', 'pull_request_id']\n",
    "display(pr_contrib)\n",
    "pr_contrib.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve PR Reviewers\n",
    "\n",
    "We will now fetch all the PR Reviewers for various repositories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prr_contrib = pd.DataFrame()\n",
    "\n",
    "for repo_id in repo_set:\n",
    "    repo_query = salc.sql.text(f\"\"\"\n",
    "                SET SCHEMA 'augur_data';\n",
    "                SELECT r.repo_id,\n",
    "                r.repo_git,\n",
    "                prr.cntrb_id,\n",
    "                prr.pull_request_id\n",
    "                FROM\n",
    "                repo r, pull_request_reviews prr\n",
    "                WHERE\n",
    "                prr.repo_id = {repo_id} AND\n",
    "                prr.repo_id = r.repo_id\n",
    "        \"\"\")\n",
    "    df_current_repo = pd.read_sql(repo_query, con=engine)\n",
    "    prr_contrib = pd.concat([prr_contrib, df_current_repo])\n",
    "\n",
    "pr_contrib = pr_contrib.reset_index()\n",
    "pr_contrib.drop(\"index\", axis=1, inplace=True)\n",
    "prr_contrib.columns =['repo_id', 'repo_git', 'cntrb_id', 'pull_request_id']\n",
    "display(prr_contrib)\n",
    "prr_contrib.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve Commit Contributors\n",
    "\n",
    "We will now fetch all the Commit contributors for various repositories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commit_contrib = pd.DataFrame()\n",
    "\n",
    "for repo_id in repo_set:\n",
    "    repo_query = salc.sql.text(f\"\"\"\n",
    "                SET SCHEMA 'augur_data';\n",
    "                SELECT r.repo_id,\n",
    "                r.repo_git,\n",
    "                ca.cntrb_id,\n",
    "                c.cmt_id\n",
    "                FROM\n",
    "                repo r, commits c, contributors_aliases ca\n",
    "                WHERE\n",
    "                c.repo_id = {repo_id} AND\n",
    "                c.repo_id = r.repo_id and\n",
    "                c.cmt_committer_email = ca.alias_email\n",
    "        \"\"\")\n",
    "    df_current_repo = pd.read_sql(repo_query, con=engine)\n",
    "    commit_contrib = pd.concat([commit_contrib, df_current_repo])\n",
    "\n",
    "commit_contrib = commit_contrib.reset_index()\n",
    "commit_contrib.drop(\"index\", axis=1, inplace=True)\n",
    "commit_contrib.columns =['repo_id', 'repo_git', 'cntrb_id', 'cmt_id']\n",
    "display(commit_contrib)\n",
    "commit_contrib.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projects and Contributors as Nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we plot projects and contributors on the same graph as nodes and color them differently to see the relationships between them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Commit Contributor Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_commit = commit_contrib.groupby(['repo_id', 'cntrb_id']).size().unstack(fill_value=0)\n",
    "df_commit.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above dataframe, each row represents a repository ID and each column represents a contributor. The dataframe contains counts for the number of times a contributor has made contributions to a particular repository. In the dataframe below `df_commit`, each contribution represents a commit. A value 0 means that a particular contributor has made no commits to the repository, and a a number x means that the contributor has made x number of commits to the repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_commit = df_commit.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_commit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_melted_commit = df_commit.melt(\n",
    "    ['repo_id'],\n",
    "    var_name = 'cntrb_id',value_name='number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_melted_commit = df_melted_commit[df_melted_commit[df_melted_commit.columns[2]] != 0]\n",
    "df_melted_commit.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In `df_melted_commit` we transpose the contributor IDs. Each row is a combination of a unique repository and a unique contributor and the number represents the number of times the contributor has made contributors to the particular repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.from_pandas_edgelist(df_melted_commit, \n",
    "                            source='repo_id',\n",
    "                            target='cntrb_id',\n",
    "                            edge_attr='number',\n",
    "                            create_using=nx.MultiGraph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = G.nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Repo_id = df_melted_commit['repo_id'].to_list()\n",
    "contributor_id = df_melted_commit['cntrb_id'].to_list()\n",
    "colors = ['blue' if n in Repo_id else 'yellow' for n in nodes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,20))\n",
    "#yellow_patch = mpatches.Patch(color='yellow', label='Contributor')\n",
    "#blue_patch = mpatches.Patch(color='blue', label='Repository')\n",
    "#ax.legend(handles=[yellow_patch, blue_patch])\n",
    "nx.draw_networkx(G, node_color=colors, with_labels=False, font_size=8, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we see above is a certain set of repositories and thier contributors plotted on the same graph. The blue dots represent project repositories and the yellow dots represent their contributors. This gives us an idea of central projects which have a large number of contributors and how other projects are connected to them. However, just given the number of repositories, this graph is hard to dig into, so lets subset this graph to create a smaller plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subsetting the first 50 repo nodes for a smaller plot\n",
    "smaller_df_melted_commit = df_melted_commit[0:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we narrow down the entire set of nodes into view only 50 nodes plotted on a graph. Note, this is just for visual simplicilty. This is not a logical filtering and not all contributors for a project are going to be seen on the same plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.from_pandas_edgelist(smaller_df_melted_commit, \n",
    "                            source='repo_id',\n",
    "                            target='cntrb_id',\n",
    "                            edge_attr='number',\n",
    "                            create_using=nx.MultiGraph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = G.nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Repo_id = smaller_df_melted_commit['repo_id'].to_list()\n",
    "contributor_id = smaller_df_melted_commit['cntrb_id'].to_list()\n",
    "colors = ['blue' if n in Repo_id else 'yellow' for n in nodes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,15))\n",
    "#ax.legend(handles=[yellow_patch, blue_patch])\n",
    "nx.draw_networkx(G, node_color=colors, with_labels=False, font_size=8, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue Contributor Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plot the plots similar to above on issue type contribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_issue = issue_contrib.groupby(['repo_id', 'cntrb_id']).size().unstack(fill_value=0)\n",
    "df_issue.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_issue = df_issue.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_issue.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_melted_issue = df_issue.melt(\n",
    "    ['repo_id'],\n",
    "    var_name = 'cntrb_id',value_name='number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_melted_issue = df_melted_issue[df_melted_issue[df_melted_issue.columns[2]] != 0]\n",
    "df_melted_issue.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Repo_id = df_melted_issue['repo_id'].to_list()\n",
    "contributor_id = df_melted_issue['cntrb_id'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.from_pandas_edgelist(df_melted_issue, \n",
    "                            source='repo_id',\n",
    "                            target='cntrb_id',\n",
    "                            edge_attr='number',\n",
    "                            create_using=nx.MultiGraph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = G.nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['blue' if n in Repo_id else 'yellow' for n in nodes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,20))\n",
    "#ax.legend(handles=[yellow_patch, blue_patch])\n",
    "nx.draw_networkx(G, node_color=colors, with_labels=False, font_size=8, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PR Contributor Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now plot similar graphs as above for Pull Request type contributors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pr = pr_contrib.groupby(['repo_id', 'cntrb_id']).size().unstack(fill_value=0)\n",
    "df_pr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pr = df_pr.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_melted_pr = df_pr.melt(\n",
    "    ['repo_id'],\n",
    "    var_name = 'cntrb_id',value_name='number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_melted_pr = df_melted_pr[df_melted_pr[df_melted_pr.columns[2]] != 0]\n",
    "df_melted_pr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Repo_id = df_melted_issue['repo_id'].to_list()\n",
    "contributor_id = df_melted_issue['cntrb_id'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.from_pandas_edgelist(df_melted_pr, \n",
    "                            source='repo_id',\n",
    "                            target='cntrb_id',\n",
    "                            edge_attr='number',\n",
    "                            create_using=nx.MultiGraph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = G.nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['blue' if n in Repo_id else 'yellow' for n in nodes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(90,90))\n",
    "pos = nx.fruchterman_reingold_layout(G)\n",
    "nx.draw_networkx(G, node_color=colors, with_labels=False, font_size=8, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nodes as projects edges as contributors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we represent data in a different way and try out another graph representation where the project repositories are represented by nodes and the edges are shared contributions between those projects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets pick the **Pull Request** type contribution for these graph plots as an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_melted_pr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contributorGraph = {}\n",
    "for i, row in df_melted_pr.iterrows():\n",
    "    if row['cntrb_id'] not in contributorGraph:\n",
    "        contributorGraph[row['cntrb_id']] = []\n",
    "    if(row['number'] > 0):\n",
    "        contributorGraph[row['cntrb_id']].append((row['repo_id'], row['number']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(contributorGraph.items())[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`contributorGraph` above is a dictionary where each key is a project repository, and the value is a list of **\"connected\"** project repositories and the number of **\"shared connections\"** between them. Lets explain **\"connected\"** repositories and shared \"connections\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "structure of `contributorGraph` =  \n",
    "{  \n",
    "`repo1`: [(`repo2`, `PRs by same authors in repo 1 and repo 2`)],  \n",
    " `repo2`: [(`repo4`, `PRs created by same authors in repo 1 and repo 4` ), (`repo5`, `PRs by same authors in repo 2 and repo 5`)]  \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\"shared connections\"** constitute of *commits*, *pull requests*, *issues* and *pull request reviews* that are made by the same contributor.\n",
    "We will call 2 project repositories **\"connected\"** if they have a **\"shared connection\"** between them. \n",
    "This means if they have a contributor who makes a *commit*, *pull request*, *issue* or *pull request review* in both the repositories, they count as a shared contributor and the repositories are connected. \n",
    "\n",
    "We track the number of shared contributions between 2 repositories for creating this graph plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commonRepoContributionsByContributor = collections.defaultdict(int)\n",
    "for key in contributorGraph:\n",
    "    if len(contributorGraph[key])-1 <= 0:\n",
    "        continue\n",
    "    for repoContributionIndex in range(len(contributorGraph[key])-1):\n",
    "        commonRepoContributionsByContributor[(contributorGraph[key][repoContributionIndex][0], contributorGraph[key][repoContributionIndex+1][0])] += contributorGraph[key][repoContributionIndex][1]+contributorGraph[key][repoContributionIndex+1][1]\n",
    "print(commonRepoContributionsByContributor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`commonRepoContributionsByContributor` is a nested dictionary consisting of dictionaries of repository pairs and their common contributions. \n",
    "\n",
    "structure of `commonRepoContributionsByContributor` =  \n",
    "{  \n",
    "(`repo1, repo2`): `PRs by same authors in repo 1 and repo 2`,  \n",
    "(`repo2, repo4`): `PRs by same authors in repo 2 and repo 4`,  \n",
    "(`repo2, repo5`): `PRs by same authors in repo 2 and repo 5`,   \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "for key in commonRepoContributionsByContributor:\n",
    "    res.append(tuple(str(k) for k in list(key)) + (commonRepoContributionsByContributor[key],))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For plotting the graph below, we pick the repositories as the nodes and let the shared contributions dictate the edge weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = nx.Graph()\n",
    "g.add_weighted_edges_from(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(30,30))\n",
    "pos = nx.fruchterman_reingold_layout(g)\n",
    "nx.draw_networkx(g, node_size=120, with_labels=False, font_size=14, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The above graph represents project repositories and how close or far they are to each other based on their degree of connected (number of shared contributions amongst them). If 2 nodes are close to each other, the 2 projects have a high number of shared contributions and vice versa. Each node in this graph has atleast one connection. We are not plotting lone projects in this graph as we want to identify project repositories in connection to existing known repositories.  \n",
    "Note: this is not a complete (fully-connected) graph. All projects are not **\"connected\"** to each project. See above for the definition of **\"connected\"** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we created initial graph representations of existing open source GitHub repositories falling under a certain category using [NetworkX](https://networkx.org/). \n",
    "\n",
    "We used 2 type of graph representations:\n",
    "\n",
    "- One where repositories and contributors both are both nodes (differently colored). Viewing which repositories share which set of contributors and analyzing their clusters can give an idea about how projects are connected to each other and to what degree \n",
    "- One where repositories are nodes, and edges are number of contributions. The distance between repositories, how close or far they are will depend on the number of shared contributions that exist between them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deps_df = pd.DataFrame()\n",
    "\n",
    "\n",
    "deps_query = salc.sql.text(f\"\"\"\n",
    "            SET SCHEMA 'augur_data';\n",
    "            SELECT\n",
    "            \tA.repo_id,\n",
    "            \tdep_name,\n",
    "            \tnumber \n",
    "            FROM\n",
    "            \t(\n",
    "            \tSELECT\n",
    "            \t\taugur_data.repo_dependencies.dep_name,\n",
    "            \t\taugur_data.repo_dependencies.repo_id,\n",
    "            \t\tCOUNT ( * ) AS number \n",
    "            \tFROM\n",
    "            \t\taugur_data.repo_dependencies \n",
    "            \tGROUP BY\n",
    "            \t\taugur_data.repo_dependencies.dep_name,\n",
    "            \t\taugur_data.repo_dependencies.repo_id \n",
    "            \tORDER BY\n",
    "            \t\tnumber DESC \n",
    "            \t) A, \n",
    "                 (                    \t\n",
    "                    SELECT C.repo_id\n",
    "                    FROM\n",
    "                        augur_operations.users A,\n",
    "                        augur_operations.user_groups b,\n",
    "                        augur_operations.user_repos C\n",
    "                    WHERE\n",
    "                        A.user_id = b.user_id \n",
    "                        AND b.group_id = C.group_id \n",
    "                        AND b.NAME = 'Google' \n",
    "                    ORDER BY\n",
    "                        A.login_name,\n",
    "                        b.group_id \n",
    "                    ) b \n",
    "                WHERE\n",
    "                    A.repo_id = b.repo_id;\n",
    "    \"\"\")\n",
    "deps_df = pd.read_sql(deps_query, con=engine)\n",
    "\n",
    "df_deps = deps_df.groupby(['repo_id', 'dep_name']).size().unstack(fill_value=0)\n",
    "\n",
    "\n",
    "display(deps_df)\n",
    "display(df_deps)\n",
    "deps_df.dtypes\n",
    "df_deps.dtypes\n",
    "\n",
    "df_deps = df_deps.reset_index()\n",
    "\n",
    "df_melted_deps = df_deps.melt(\n",
    "    ['repo_id'],\n",
    "     var_name='dep_name', value_name='depcount') \n",
    "\n",
    "df_melted_deps = df_melted_deps[df_melted_deps[df_melted_deps.columns[2]] != 0]\n",
    "\n",
    "\n",
    "display(df_melted_deps)\n",
    "\n",
    "G = nx.from_pandas_edgelist(df_melted_deps, \n",
    "                            source='dep_name',\n",
    "                            target='repo_id',\n",
    "                            create_using=nx.MultiGraph())\n",
    "\n",
    "nodes = G.nodes()\n",
    "#print(nodes)\n",
    "\n",
    "\n",
    "Repo_id = df_melted_deps['repo_id'].to_list()\n",
    "dep_name = df_melted_deps['dep_name'].to_list()\n",
    "#colors = ['red' if n in repo_id else 'yellow' for n in nodes]\n",
    "#node_size = [depcount if n in dep_name else 120 if n in nodes]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(90,90))\n",
    "pos = nx.fruchterman_reingold_layout(G)\n",
    "nx.draw_networkx(G, with_labels=False, font_size=14, ax=ax)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
