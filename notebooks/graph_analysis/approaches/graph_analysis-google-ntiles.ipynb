{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graphical Analysis of GitHub Repositories and Contributors\n",
    "\n",
    "In this notebook, we programatically view the connections between open source projects, determine project clusters, and map out technology ecosystems. We explore the Augur GitHub data to view relationships between open source projects and communities by studying graphs based on relations such as common contributors and project activities between different GitHub repositories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Augur database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Until the Operate First enviroment can connect to the DB, use config file to access. Do not push config file to Github repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "import collections\n",
    "from functools import reduce\n",
    "import datetime\n",
    "\n",
    "import sqlalchemy as salc\n",
    "import json\n",
    "import os\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "with open(\"../../../config.json\") as config_file:\n",
    "    config = json.load(config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_connection_string = 'postgresql+psycopg2://{}:{}@{}:{}/{}'.format(config['user'], config['password'], config['host'], config['port'], config['database'])\n",
    "\n",
    "dbschema='augur_data'\n",
    "engine = salc.create_engine(\n",
    "    database_connection_string,\n",
    "    connect_args={'options': '-csearch_path={}'.format(dbschema)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get all the Data, Build all the Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset repositories based on a category\n",
    "# Selecting repositories that fall under the Containers org on Github\n",
    "science_repo_sql = salc.sql.text(f\"\"\"\n",
    "                 SET SCHEMA 'augur_data';\n",
    "                    --science \n",
    "                    SELECT\n",
    "                    \trepo_git, ntile(10) over ( order by commits_all_time) \n",
    "                    FROM\n",
    "                    \trepo A,\n",
    "                    \t(\n",
    "                    \tSELECT C.repo_id, d.commits_all_time\n",
    "                    \tFROM\n",
    "                    \t\taugur_operations.users A,\n",
    "                    \t\taugur_operations.user_groups b,\n",
    "                    \t\taugur_operations.user_repos C, \n",
    "                    \t\tapi_get_all_repos_commits d \n",
    "                    \tWHERE\n",
    "                    \t\tA.user_id = b.user_id \n",
    "                    \t\tAND b.group_id = C.group_id \n",
    "                    \t\tAND d.repo_id= c.repo_id\n",
    "                    \t\tAND b.NAME = 'Google' --AND lower(A.login_name)='numfocus'\n",
    "                    \t\t\n",
    "                    \tORDER BY\n",
    "                    \t\tA.login_name,\n",
    "                    \t\td.commits_all_time,\n",
    "                    \t\tb.group_id \n",
    "                    \t) b \n",
    "                    WHERE\n",
    "                    \tA.repo_id = b.repo_id order by commits_all_time desc\n",
    "                            \"\"\")\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    #df = pd.read_sql(sql, cnxn)\n",
    "    results = conn.execute(science_repo_sql)\n",
    "    df_results = pd.DataFrame(results) \n",
    "\n",
    "print(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find unique ntile values\n",
    "ntiles = df_results.ntile.unique()\n",
    "display(df_results) \n",
    "#sort values smallest to largest\n",
    "ntiles.sort()\n",
    "\n",
    "#display sorted values\n",
    "display(ntiles)\n",
    "\n",
    "#run analysis in ntiles\n",
    "#surveys_df[surveys_df.year == 2002]\n",
    "\n",
    "for i in ntiles:\n",
    "    repo_set=[]\n",
    "    repo_git_set = []\n",
    "    repo_name_set = []\n",
    "    result_tile = df_results[df_results.ntile==i]\n",
    "    #print(i)\n",
    "    #print(result_tile)\n",
    "\n",
    "    \n",
    "    print(\"Graphs for NTILE: \" + str(i))\n",
    "    print('Starting Data Collection for NTILE: ' + str(i))\n",
    "    ct = datetime.datetime.now()\n",
    "    print(\"current time:-\", ct)\n",
    "\n",
    "#    for index, row in result_tile.iterrows():\n",
    "    for row in result_tile.itertuples(index = True):\n",
    "        trepo_git=getattr(row,\"repo_git\")\n",
    "        display(trepo_git)\n",
    "        repo_query = salc.sql.text(f\"\"\"\n",
    "                     SET SCHEMA 'augur_data';\n",
    "                     SELECT \n",
    "                        b.repo_id,\n",
    "                        b.repo_name\n",
    "                    FROM\n",
    "                        repo_groups a,\n",
    "                        repo b\n",
    "                    WHERE\n",
    "                        a.repo_group_id = b.repo_group_id AND\n",
    "                        b.repo_git = '{trepo_git}'\n",
    "            \"\"\")\n",
    "        with engine.connect() as conn:\n",
    "            results = conn.execute(repo_query)\n",
    "            df2_results = pd.DataFrame(results) \n",
    "        df2_results.reset_index(drop=True, inplace=True) \n",
    "        repo_id = int(df2_results['repo_id'].values[0])\n",
    "        repo_name = df2_results['repo_name'].to_string(index=False)\n",
    "        repo_set.append(repo_id)\n",
    "        repo_name_set.append(repo_name)\n",
    "        repo_git_set.append(trepo_git)    \n",
    "\n",
    "        #Issue Contributors\n",
    "        issue_contrib = pd.DataFrame()\n",
    "        for repo_id in repo_set:\n",
    "            repo_query = salc.sql.text(f\"\"\"\n",
    "                        SET SCHEMA 'augur_data';\n",
    "                        SELECT r.repo_id,\n",
    "                        r.repo_git,\n",
    "                        i.reporter_id as cntrb_id,\n",
    "                        i.issue_id\n",
    "                        FROM\n",
    "                        repo r, issues i\n",
    "                         WHERE\n",
    "                        i.repo_id = {repo_id} AND\n",
    "                        i.repo_id = r.repo_id\n",
    "                \"\"\")\n",
    "            df_current_repo = pd.read_sql(repo_query, con=engine)\n",
    "            issue_contrib = pd.concat([issue_contrib, df_current_repo])\n",
    "        \n",
    "        issue_contrib = issue_contrib.reset_index()\n",
    "        issue_contrib.drop(\"index\", axis=1, inplace=True)\n",
    "        issue_contrib.columns =['repo_id', 'repo_git', 'cntrb_id', 'issue_id']\n",
    "        #display(issue_contrib)\n",
    "        #issue_contrib.dtypes    \n",
    "    \n",
    "        #PR Contributors\n",
    "        pr_contrib = pd.DataFrame()\n",
    "        \n",
    "        for repo_id in repo_set:\n",
    "            repo_query = salc.sql.text(f\"\"\"\n",
    "                        SET SCHEMA 'augur_data';\n",
    "                        SELECT r.repo_id,\n",
    "                        r.repo_git,\n",
    "                        prm.cntrb_id,\n",
    "                        prm.pull_request_id\n",
    "                        FROM\n",
    "                        repo r, pull_request_meta prm\n",
    "                        WHERE\n",
    "                        prm.repo_id = {repo_id} AND\n",
    "                        prm.repo_id = r.repo_id\n",
    "                \"\"\")\n",
    "            df_current_repo = pd.read_sql(repo_query, con=engine)\n",
    "            pr_contrib = pd.concat([pr_contrib, df_current_repo])\n",
    "        \n",
    "        pr_contrib = pr_contrib.reset_index()\n",
    "        pr_contrib.drop(\"index\", axis=1, inplace=True)\n",
    "        pr_contrib.columns =['repo_id', 'repo_git', 'cntrb_id', 'pull_request_id']\n",
    "        #display(pr_contrib)\n",
    "        #pr_contrib.dtypes\n",
    "\n",
    "    \n",
    "        #PR Reviewers\n",
    "        prr_contrib = pd.DataFrame()\n",
    "        \n",
    "        for repo_id in repo_set:\n",
    "            repo_query = salc.sql.text(f\"\"\"\n",
    "                        SET SCHEMA 'augur_data';\n",
    "                        SELECT r.repo_id,\n",
    "                        r.repo_git,\n",
    "                        prr.cntrb_id,\n",
    "                        prr.pull_request_id\n",
    "                        FROM\n",
    "                        repo r, pull_request_reviews prr\n",
    "                        WHERE\n",
    "                        prr.repo_id = {repo_id} AND\n",
    "                        prr.repo_id = r.repo_id\n",
    "                \"\"\")\n",
    "            df_current_repo = pd.read_sql(repo_query, con=engine)\n",
    "            prr_contrib = pd.concat([prr_contrib, df_current_repo])\n",
    "        \n",
    "        pr_contrib = pr_contrib.reset_index()\n",
    "        pr_contrib.drop(\"index\", axis=1, inplace=True)\n",
    "        prr_contrib.columns =['repo_id', 'repo_git', 'cntrb_id', 'pull_request_id']\n",
    "        #display(prr_contrib)\n",
    "        #prr_contrib.dtypes\n",
    "\n",
    "    \n",
    "        # Commit Contributors\n",
    "        commit_contrib = pd.DataFrame()\n",
    "        \n",
    "        for repo_id in repo_set:\n",
    "            repo_query = salc.sql.text(f\"\"\"\n",
    "                        SET SCHEMA 'augur_data';\n",
    "                        SELECT r.repo_id,\n",
    "                        r.repo_git,\n",
    "                        ca.cntrb_id,\n",
    "                        c.cmt_id\n",
    "                        FROM\n",
    "                        repo r, commits c, contributors_aliases ca\n",
    "                        WHERE\n",
    "                        c.repo_id = {repo_id} AND\n",
    "                        c.repo_id = r.repo_id and\n",
    "                        c.cmt_committer_email = ca.alias_email\n",
    "                \"\"\")\n",
    "            df_current_repo = pd.read_sql(repo_query, con=engine)\n",
    "            commit_contrib = pd.concat([commit_contrib, df_current_repo])\n",
    "        \n",
    "        commit_contrib = commit_contrib.reset_index()\n",
    "        commit_contrib.drop(\"index\", axis=1, inplace=True)\n",
    "        commit_contrib.columns =['repo_id', 'repo_git', 'cntrb_id', 'cmt_id']\n",
    "        #display(commit_contrib)\n",
    "        #commit_contrib.dtypes\n",
    "\n",
    "###########################################################################\n",
    "\n",
    "    print('Completed Data Collection for NTILE: ' + str(i))\n",
    "    ct = datetime.datetime.now()\n",
    "    print(\"current time:-\", ct)\n",
    "    \n",
    "    # Commit Contributor Graph\n",
    "    df_commit = commit_contrib.groupby(['repo_id', 'cntrb_id']).size().unstack(fill_value=0)\n",
    "    df_commit.head()\n",
    "    df_commit = df_commit.reset_index()\n",
    "    \n",
    "    df_melted_commit = df_commit.melt(\n",
    "        ['repo_id'],\n",
    "        var_name = 'cntrb_id',value_name='number')\n",
    "    \n",
    "    df_melted_commit = df_melted_commit[df_melted_commit[df_melted_commit.columns[2]] != 0]\n",
    "    df_melted_commit.head()\n",
    "    G = nx.from_pandas_edgelist(df_melted_commit, \n",
    "                                source='repo_id',\n",
    "                                target='cntrb_id',\n",
    "                                edge_attr='number',\n",
    "                                create_using=nx.MultiGraph())\n",
    "    nodes = G.nodes()\n",
    "    Repo_id = df_melted_commit['repo_id'].to_list()\n",
    "    contributor_id = df_melted_commit['cntrb_id'].to_list()\n",
    "    colors = ['blue' if n in Repo_id else 'yellow' for n in nodes]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(20,20))\n",
    "    #yellow_patch = mpatches.Patch(color='yellow', label='Contributor')\n",
    "    #blue_patch = mpatches.Patch(color='blue', label='Repository')\n",
    "    #ax.legend(handles=[yellow_patch, blue_patch])\n",
    "    print('commit contributor graph')\n",
    "    ts = time.time()\n",
    "    print(ts)         \n",
    "\n",
    "    pos = nx.fruchterman_reingold_layout(G)\n",
    "    spos = nx.spring_layout(G, pos=pos, k=.4)\n",
    "    anonygraph = nx.draw_networkx(G, node_color=colors, with_labels=False, pos=spos, alpha=0.2, font_size=7, ax=ax)\n",
    "    filename = \"commit_contributor_graph_ntile_\" + str(i) +\".png\"\n",
    "    plt.savefig(fname=filename, format=\"png\")\n",
    "    plt.show(nx.draw_networkx(G, node_color=colors, pos=spos, with_labels=False, alpha=0.2, font_size=7, ax=ax))\n",
    "    nx.draw_networkx(G, node_color=colors, with_labels=False, pos=spos, alpha=0.2, font_size=7, ax=ax)   \n",
    "    \n",
    "    #nx.draw_networkx(G, node_color=colors, with_labels=False, font_size=8, ax=ax)\n",
    "    print('Graph for commit contributors should have just printed')\n",
    "    ct = datetime.datetime.now()\n",
    "    print(\"current time:-\", ct)\n",
    "\n",
    "    # Issue Contributor Graph\n",
    "    df_issue = issue_contrib.groupby(['repo_id', 'cntrb_id']).size().unstack(fill_value=0)\n",
    "    df_issue = df_issue.reset_index()\n",
    "    df_melted_issue = df_issue.melt(\n",
    "        ['repo_id'],\n",
    "        var_name = 'cntrb_id',value_name='number')\n",
    "    Repo_id = df_melted_issue['repo_id'].to_list()\n",
    "    contributor_id = df_melted_issue['cntrb_id'].to_list()\n",
    "    \n",
    "    G = nx.from_pandas_edgelist(df_melted_issue, \n",
    "                                source='repo_id',\n",
    "                                target='cntrb_id',\n",
    "                                edge_attr='number',\n",
    "                                create_using=nx.MultiGraph())\n",
    "    nodes = G.nodes()\n",
    "    colors = ['blue' if n in Repo_id else 'yellow' for n in nodes]\n",
    "    fig, ax = plt.subplots(figsize=(20,20))\n",
    "    #ax.legend(handles=[yellow_patch, blue_patch])\n",
    "    print('issue contributor graph')\n",
    "    ts = time.time()\n",
    "    print(ts)     \n",
    "\n",
    "    pos = nx.fruchterman_reingold_layout(G)\n",
    "    spos = nx.spring_layout(G, pos=pos, k=.4)\n",
    "    anonygraph = nx.draw_networkx(G, node_color=colors, with_labels=False, pos=spos, alpha=0.2, font_size=7, ax=ax)\n",
    "    filename = \"issue_contributor_graph_ntile_\" + str(i) +\".png\"\n",
    "    plt.savefig(fname=filename, format=\"png\")\n",
    "    plt.show(nx.draw_networkx(G, node_color=colors, pos=spos, with_labels=False, alpha=0.2, font_size=7, ax=ax))\n",
    "    nx.draw_networkx(G, node_color=colors, with_labels=False, pos=spos, alpha=0.2, font_size=7, ax=ax)   \n",
    "\n",
    "    \n",
    "    print('Graph for issue contributors should have just printed')\n",
    "    ct = datetime.datetime.now()\n",
    "    print(\"current time:-\", ct)\n",
    "\n",
    "    ### PR Contributor Graph\n",
    "    df_pr = pr_contrib.groupby(['repo_id', 'cntrb_id']).size().unstack(fill_value=0)\n",
    "    df_pr = df_pr.reset_index()\n",
    "    df_melted_pr = df_pr.melt(\n",
    "        ['repo_id'],\n",
    "        var_name = 'cntrb_id',value_name='number')\n",
    "\n",
    "    df_melted_pr = df_melted_pr[df_melted_pr[df_melted_pr.columns[2]] != 0]\n",
    "    Repo_id = df_melted_issue['repo_id'].to_list()\n",
    "    contributor_id = df_melted_issue['cntrb_id'].to_list()\n",
    "    \n",
    "    G = nx.from_pandas_edgelist(df_melted_pr, \n",
    "                                source='repo_id',\n",
    "                                target='cntrb_id',\n",
    "                                edge_attr='number',\n",
    "                                create_using=nx.MultiGraph())\n",
    "\n",
    "    nodes = G.nodes()\n",
    "    colors = ['blue' if n in Repo_id else 'yellow' for n in nodes]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(20,20))\n",
    "    pos = nx.fruchterman_reingold_layout(G)\n",
    "    print('PR contributor graph')\n",
    "    ts = time.time()\n",
    "    print(ts)     \n",
    "\n",
    "    pos = nx.fruchterman_reingold_layout(G)\n",
    "    spos = nx.spring_layout(G, pos=pos, k=.4)\n",
    "    anonygraph = nx.draw_networkx(G, node_color=colors, with_labels=False, pos=spos, alpha=0.2, font_size=7, ax=ax)\n",
    "    filename = \"PR_contributor_graph_ntile_\" + str(i) +\".png\"\n",
    "    plt.savefig(fname=filename, format=\"png\")\n",
    "    plt.show(nx.draw_networkx(G, node_color=colors, pos=spos, with_labels=False, alpha=0.2, font_size=7, ax=ax))\n",
    "    nx.draw_networkx(G, node_color=colors, with_labels=False, pos=spos, alpha=0.2, font_size=7, ax=ax)   \n",
    "    \n",
    "    print('Graph for PR contributors should have just printed')\n",
    "    ct = datetime.datetime.now()\n",
    "    print(\"current time:-\", ct)\n",
    "\n",
    "    ## Nodes as projects edges as contributors\n",
    "    #  In this section, we represent data differently and try out another graph representation where the project repositories are represented by nodes, and the edges are shared contributions between those projects\n",
    "\n",
    "    print('contributor graph: Nodes as projects, edges as contributors')\n",
    "    #    print(`contributorGraph` above is a dictionary where each key is a project repository, and the value is a list of **\"connected\"** project repositories and the number of **\"shared connections\"** between them. Lets explain **\"connected\"** repositories and shared \"connections\".)\n",
    "    #**\"shared connections\"** constitute of *commits*, *pull requests*, *issues* and *pull request reviews* that are made by the same contributor.\n",
    "    #We will call 2 project repositories **\"connected\"** if they have a **\"shared connection\"** between them. \n",
    "    #This means if they have a contributor who makes a *commit*, *pull request*, *issue* or *pull request review* in both the repositories, they count as a shared contributor and the repositories are connected. \n",
    "\n",
    "    #structure of `contributorGraph` =  \n",
    "       # {  \n",
    "       # `repo1`: [(`repo2`, `PRs by same authors in repo 1 and repo 2`)],  \n",
    "       # `repo2`: [(`repo4`, `PRs created by same authors in repo 1 and repo 4` ), (`repo5`, `PRs by same authors in repo 2 and repo 5`)]  \n",
    "       # }\n",
    "\n",
    "#We track the number of shared contributions between 2 repositories for creating this graph plot.\n",
    "    contributorGraph = {}\n",
    "    for i, row in df_melted_pr.iterrows():\n",
    "        if row['cntrb_id'] not in contributorGraph:\n",
    "            contributorGraph[row['cntrb_id']] = []\n",
    "        if(row['number'] > 0):\n",
    "            contributorGraph[row['cntrb_id']].append((row['repo_id'], row['number']))\n",
    "\n",
    "    commonRepoContributionsByContributor = collections.defaultdict(int)\n",
    "    for key in contributorGraph:\n",
    "        if len(contributorGraph[key])-1 <= 0:\n",
    "            continue\n",
    "        for repoContributionIndex in range(len(contributorGraph[key])-1):\n",
    "            commonRepoContributionsByContributor[(contributorGraph[key][repoContributionIndex][0], contributorGraph[key][repoContributionIndex+1][0])] += contributorGraph[key][repoContributionIndex][1]+contributorGraph[key][repoContributionIndex+1][1]\n",
    "    res = []\n",
    "    for key in commonRepoContributionsByContributor:\n",
    "        res.append(tuple(str(k) for k in list(key)) + (commonRepoContributionsByContributor[key],))\n",
    "\n",
    "    G = nx.Graph()\n",
    "    G.add_weighted_edges_from(res)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(30,30))\n",
    "\n",
    "    pos = nx.fruchterman_reingold_layout(G)\n",
    "    spos = nx.spring_layout(G, pos=pos, k=.4)\n",
    "    anonygraph = nx.draw_networkx(G, node_color=colors, with_labels=False, pos=spos, alpha=0.2, font_size=7, ax=ax)\n",
    "    filename = \"2_repo_contributors_contributor_graph_ntile_\" + str(i) +\".png\"\n",
    "    plt.savefig(fname=filename, format=\"png\")\n",
    "    plt.show(nx.draw_networkx(G, node_color=colors, pos=spos, with_labels=False, alpha=0.2, font_size=7, ax=ax))\n",
    "    nx.draw_networkx(G, node_color=colors, with_labels=False, pos=spos, alpha=0.2, font_size=7, ax=ax)   \n",
    "    \n",
    "\n",
    "    ts = time.time()\n",
    "    print(ts)     \n",
    "    nx.draw_networkx(g, node_size=120, with_labels=False, font_size=14, ax=ax)\n",
    "    print('Graph for Nodes:Projects, Edges: Contributors should have just printed')\n",
    "    ct = datetime.datetime.now()\n",
    "    print(\"current time:-\", ct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The above graph represents project repositories and how close or far they are to each other based on their degree of connected (number of shared contributions amongst them). If 2 nodes are close to each other, the 2 projects have a high number of shared contributions and vice versa. Each node in this graph has atleast one connection. We are not plotting lone projects in this graph as we want to identify project repositories in connection to existing known repositories.  \n",
    "Note: this is not a complete (fully-connected) graph. All projects are not **\"connected\"** to each project. See above for the definition of **\"connected\"** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we created initial graph representations of existing open source GitHub repositories falling under a certain category using [NetworkX](https://networkx.org/). \n",
    "\n",
    "We used 2 type of graph representations:\n",
    "\n",
    "- One where repositories and contributors both are both nodes (differently colored). Viewing which repositories share which set of contributors and analyzing their clusters can give an idea about how projects are connected to each other and to what degree \n",
    "- One where repositories are nodes, and edges are number of contributions. The distance between repositories, how close or far they are will depend on the number of shared contributions that exist between them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deps_df = pd.DataFrame()\n",
    "\n",
    "\n",
    "deps_query = salc.sql.text(f\"\"\"\n",
    "            SET SCHEMA 'augur_data';\n",
    "            SELECT\n",
    "            \tA.repo_id,\n",
    "            \tdep_name,\n",
    "            \tnumber \n",
    "            FROM\n",
    "            \t(\n",
    "            \tSELECT\n",
    "            \t\taugur_data.repo_dependencies.dep_name,\n",
    "            \t\taugur_data.repo_dependencies.repo_id,\n",
    "            \t\tCOUNT ( * ) AS number \n",
    "            \tFROM\n",
    "            \t\taugur_data.repo_dependencies \n",
    "            \tGROUP BY\n",
    "            \t\taugur_data.repo_dependencies.dep_name,\n",
    "            \t\taugur_data.repo_dependencies.repo_id \n",
    "            \tORDER BY\n",
    "            \t\tnumber DESC \n",
    "            \t) A, \n",
    "                 (                    \t\n",
    "                    SELECT C.repo_id\n",
    "                    FROM\n",
    "                        augur_operations.users A,\n",
    "                        augur_operations.user_groups b,\n",
    "                        augur_operations.user_repos C\n",
    "                    WHERE\n",
    "                        A.user_id = b.user_id \n",
    "                        AND b.group_id = C.group_id \n",
    "                        AND b.NAME = 'Google' \n",
    "                    ORDER BY\n",
    "                        A.login_name,\n",
    "                        b.group_id \n",
    "                    ) b \n",
    "                WHERE\n",
    "                    A.repo_id = b.repo_id;\n",
    "    \"\"\")\n",
    "deps_df = pd.read_sql(deps_query, con=engine)\n",
    "\n",
    "df_deps = deps_df.groupby(['repo_id', 'dep_name']).size().unstack(fill_value=0)\n",
    "\n",
    "\n",
    "display(deps_df)\n",
    "display(df_deps)\n",
    "deps_df.dtypes\n",
    "df_deps.dtypes\n",
    "\n",
    "df_deps = df_deps.reset_index()\n",
    "\n",
    "df_melted_deps = df_deps.melt(\n",
    "    ['repo_id'],\n",
    "     var_name='dep_name', value_name='depcount') \n",
    "\n",
    "df_melted_deps = df_melted_deps[df_melted_deps[df_melted_deps.columns[2]] != 0]\n",
    "\n",
    "\n",
    "display(df_melted_deps)\n",
    "\n",
    "G = nx.from_pandas_edgelist(df_melted_deps, \n",
    "                            source='dep_name',\n",
    "                            target='repo_id',\n",
    "                            create_using=nx.MultiGraph())\n",
    "\n",
    "nodes = G.nodes()\n",
    "#print(nodes)\n",
    "\n",
    "\n",
    "Repo_id = df_melted_deps['repo_id'].to_list()\n",
    "dep_name = df_melted_deps['dep_name'].to_list()\n",
    "#colors = ['red' if n in repo_id else 'yellow' for n in nodes]\n",
    "#node_size = [depcount if n in dep_name else 120 if n in nodes]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(90,90))\n",
    "pos = nx.fruchterman_reingold_layout(G)\n",
    "nx.draw_networkx(G, with_labels=False, font_size=14, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"commit_contributor_graph_ntile_\" + str(i) +\".png\"\n",
    "print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
